#!/usr/bin/python3

import time
import random
import os
import re
import glob
import yaml
import json
import psutil
import datetime
import redis
from functools import reduce
from prometheus_client.core import GaugeMetricFamily, REGISTRY, CounterMetricFamily
from prometheus_client import start_http_server

Cfg={ 'Port': 9000, 'Freq': 1, 'Collect': [], 'Tags': [] }

class CollectCPU(object):
    def __init__(self):
        self.kTags=[ k for lin in (t.keys() for t in Cfg['Tags']) for k in lin ]
        self.vTags=[ v for lin in (t.values() for t in Cfg['Tags']) for v in lin ]
    def defs(self,obj,k):
        return getattr(obj,k) if hasattr(obj, k) else 0
    def collect(self):
        if "cpu.times" in Cfg['Collect']:
           cpu=psutil.cpu_times()
           ct_us = CounterMetricFamily("cpu_times_user", "time spent by normal processes executing in user mode", labels=self.kTags)
           ct_us.add_metric(self.vTags, cpu.user)
           ct_sy = CounterMetricFamily("cpu_times_system", "time spent by processes executing in kernel mode", labels=self.kTags)
           ct_sy.add_metric(self.vTags, cpu.system)
           ct_id = CounterMetricFamily("cpu_times_idle", "time spent doing nothing", labels=self.kTags)
           ct_id.add_metric(self.vTags, cpu.idle)
           ct_nc = CounterMetricFamily("cpu_times_nice", "time spent by niced (prioritized) processes executing in user mode", labels=self.kTags)
           ct_nc.add_metric(self.vTags, cpu.nice)
           ct_io = CounterMetricFamily("cpu_times_iowait", "time spent waiting for I/O to complete", labels=self.kTags)
           ct_io.add_metric(self.vTags, self.defs(cpu,"iowait"))
           ct_iq = CounterMetricFamily("cpu_times_irq", "time spent for servicing hardware interrupts", labels=self.kTags)
           ct_iq.add_metric(self.vTags, cpu.irq)
           ct_sf = CounterMetricFamily("cpu_times_softirq", "time spent for servicing software interrupts", labels=self.kTags)
           ct_sf.add_metric(self.vTags, cpu.softirq)
           ct_st = CounterMetricFamily("cpu_times_steal", "time spent by other O.S. running in a virtualized environment", labels=self.kTags)
           ct_st.add_metric(self.vTags, cpu.steal)
           ct_ge = CounterMetricFamily("cpu_times_guest", "time spent running a virtual CPU for guest operating systems", labels=self.kTags)
           ct_ge.add_metric(self.vTags, cpu.guest)
           yield from (ct_us, ct_sy, ct_id, ct_nc, ct_io, ct_iq, ct_sf, ct_st, ct_ge)

        if "cpu.stats" in Cfg['Collect']:
           cpu=psutil.cpu_stats()
           cs_sw = CounterMetricFamily("cpu_stat_ctx_switches", "number of context switches since boot.", labels=self.kTags)
           cs_sw.add_metric(self.vTags, cpu.ctx_switches)
           cs_it = CounterMetricFamily("cpu_stat_interrupts", "number of interrupts since boot", labels=self.kTags)
           cs_it.add_metric(self.vTags, cpu.interrupts)
           cs_sf = CounterMetricFamily("cpu_stat_soft_interrupts", "number of software interrupts since boot", labels=self.kTags)
           cs_sf.add_metric(self.vTags, cpu.soft_interrupts)
           cs_sy = CounterMetricFamily("cpu_stat_syscalls", "number of system calls since boot", labels=self.kTags)
           cs_sy.add_metric(self.vTags, cpu.syscalls)
           yield from (cs_sw, cs_it, cs_sf, cs_sy)

        ncpu = GaugeMetricFamily("cpu_count", "Return the number of logical CPUs", labels=self.kTags)
        ncpu.add_metric(self.vTags, psutil.cpu_count())
        yield ncpu

        if "cpu.freq" in Cfg['Collect']:
           cpu=psutil.cpu_freq()
           lbl=self.kTags.copy(); lbl.extend(["Minimum","Maximum"])
           val=self.vTags.copy(); val.extend([str(cpu.min), str(cpu.max)])
           cf_cu = GaugeMetricFamily("cpu_freq", "CPU frequency, expressed in Mhz", labels=lbl)
           cf_cu.add_metric(val, cpu.current)
           yield cf_cu

        if "cpu.load" in Cfg['Collect']:
           cpu=[x / psutil.cpu_count() * 100 for x in psutil.getloadavg()]
           cl_1 = GaugeMetricFamily("cpu_load_1m", "System load average over last minute", labels=self.kTags)
           cl_1.add_metric(self.vTags, cpu[0])
           cl_5 = GaugeMetricFamily("cpu_load_5m", "System load average over last 5 minutes", labels=self.kTags)
           cl_5.add_metric(self.vTags, cpu[1])
           cl_15 = GaugeMetricFamily("cpu_load_15m", "System load average over last 15 minutes", labels=self.kTags)
           cl_15.add_metric(self.vTags, cpu[2])
           yield from (cl_1, cl_5, cl_15)

        if "memory" in Cfg['Collect']:
           mem=psutil.virtual_memory()
           m_used = GaugeMetricFamily("memory_used", "memory used", labels=self.kTags)
           m_used.add_metric(self.vTags, mem.used)
           m_free = GaugeMetricFamily("memory_free", "memory not being used at all, that is readily available", labels=self.kTags)
           m_free.add_metric(self.vTags, mem.free)
           m_act = GaugeMetricFamily("memory_active", "memory currently in use or very recently used", labels=self.kTags)
           m_act.add_metric(self.vTags, mem.active)
           m_inact = GaugeMetricFamily("memory_inactive", "memory that is marked as not used", labels=self.kTags)
           m_inact.add_metric(self.vTags, mem.inactive)
           m_buff = GaugeMetricFamily("memory_buffers", "cache for things like file system metadata", labels=self.kTags)
           m_buff.add_metric(self.vTags, mem.buffers)
           m_cache = GaugeMetricFamily("memory_cached", "cache for various things", labels=self.kTags)
           m_cache.add_metric(self.vTags, mem.cached)
           m_shared = GaugeMetricFamily("memory_shared", "memory that may be simultaneously accessed by multiple processes", labels=self.kTags)
           m_shared.add_metric(self.vTags, mem.shared)
           m_slab = GaugeMetricFamily("memory_slab", "in-kernel data structures cache", labels=self.kTags)
           m_slab.add_metric(self.vTags, mem.slab)
           yield from (m_used, m_free, m_act, m_inact, m_buff, m_cache, m_shared, m_slab)

        if "swap" in Cfg['Collect']:
           swp=psutil.swap_memory()
           s_total = GaugeMetricFamily("swap_total", "total swap memory in bytes", labels=self.kTags)
           s_total.add_metric(self.vTags, swp.total)
           s_used = GaugeMetricFamily("swap_used", "used swap memory in bytes", labels=self.kTags)
           s_used.add_metric(self.vTags, swp.used)
           s_free = GaugeMetricFamily("swap_free", "free swap memory in bytes", labels=self.kTags)
           s_free.add_metric(self.vTags, swp.free)
           s_perc = GaugeMetricFamily("swap_percent", "the percentage usage calculated as (total - available) / total * 100", labels=self.kTags)
           s_perc.add_metric(self.vTags, swp.percent)
           s_in = CounterMetricFamily("swap_buffers", "the number of bytes the system has swapped in from disk", labels=self.kTags)
           s_in.add_metric(self.vTags, swp.sin)
           s_out = CounterMetricFamily("swap_out", "the number of bytes the system has swapped out from disk", labels=self.kTags)
           s_out.add_metric(self.vTags, swp.sout)
           yield from (s_total, s_used, s_free, s_perc, s_in, s_out)

        mdisk=list(filter(lambda x: x!="disk",reduce(lambda a,b: a+b.split(), filter(lambda x: x.startswith("disk "), Cfg['Collect']) ,[] )))
        for disk in mdisk:
           duse=psutil.disk_usage(disk)
           lbl=self.kTags.copy(); lbl.extend(["MountPoint"])
           val=self.vTags.copy(); val.extend([disk])
           d_total = GaugeMetricFamily("disk_total", "Total disk space in bytes", labels=lbl)
           d_total.add_metric(val, duse.total)
           d_used = GaugeMetricFamily("disk_used", "Used disk space in bytes", labels=lbl)
           d_used.add_metric(val, duse.used)
           d_free = GaugeMetricFamily("disk_free", "Free disk space in bytes", labels=lbl)
           d_free.add_metric(val, duse.free)
           d_perc = GaugeMetricFamily("disk_percent", "the percentage usage calculated as (total - used) / total * 100", labels=lbl)
           d_perc.add_metric(val, duse.percent)
           yield from (d_total, d_used, d_free, d_perc)

        mnic=list(filter(lambda x: x!="nic",reduce(lambda a,b: a+b.split(), filter(lambda x: x.startswith("nic "), Cfg['Collect']) ,[] )))
        if mnic:
           dnic=psutil.net_io_counters(pernic=True)
           for nic in mnic:
              if nic in dnic:
                 lbl=self.kTags.copy(); lbl.extend(["nic"])
                 val=self.vTags.copy(); val.extend([nic])
                 nb_send = GaugeMetricFamily("bytes_sent", "number of bytes sent", labels=lbl)
                 nb_send.add_metric(val, dnic[nic].bytes_sent)
                 nb_recv = GaugeMetricFamily("bytes_recv", "number of bytes received", labels=lbl)
                 nb_recv.add_metric(val, dnic[nic].bytes_recv)
                 np_send = GaugeMetricFamily("packets_sent", "number of packets sent", labels=lbl)
                 np_send.add_metric(val, dnic[nic].packets_sent)
                 np_recv = GaugeMetricFamily("packets_recv", "number of packets received", labels=lbl)
                 np_recv.add_metric(val, dnic[nic].packets_recv)
                 ne_in = GaugeMetricFamily("errors_in", "total number of errors while receiving", labels=lbl)
                 ne_in.add_metric(val, dnic[nic].errin)
                 ne_out = GaugeMetricFamily("errors_out", "total number of errors while sending", labels=lbl)
                 ne_out.add_metric(val, dnic[nic].errout)
                 nd_in = GaugeMetricFamily("drop_in", "total number of incoming packets which were dropped", labels=lbl)
                 nd_in.add_metric(val, dnic[nic].dropin)
                 nd_out = GaugeMetricFamily("drop_out", "total number of outgoing packets which were dropped", labels=lbl)
                 nd_out.add_metric(val, dnic[nic].dropout)
                 yield from (nb_send, nb_recv, np_send, np_recv, ne_in, ne_out, nd_in, nd_out)

        mport=list(filter(lambda x: x!="port",reduce(lambda a,b: a+b.split(), filter(lambda x: x.startswith("port "), Cfg['Collect']) ,[] )))
        if mport:
           ps=list(filter(lambda a: str(a.raddr.port) in mport or str(a.laddr.port) in mport,[ b for b in psutil.net_connections(kind="tcp4") if b.raddr ]))
           Procs={}
           Stats={}
           for p in ps:
               Stats[p.status]=1 if p.status not in Stats else Stats[p.status]+1
               if p.pid:
                  Procs[p.pid]=1 if p.pid not in Procs else Procs[p.pid]+1
           rProcs=[]
           for p in Procs.keys():
               proc=psutil.Process(pid=p).as_dict(attrs=['name', 'io_counters', 'num_fds', 'threads', 'cpu_percent', 'connections', 'pid', 'cmdline', 'cpu_times',  'memory_full_info', 'num_ctx_switches', 'create_time', 'memory_percent', 'num_threads', 'cpu_num', 'status' ])
               lbl=self.kTags.copy(); lbl.extend(["name","pid","command","create_time"])
               val=self.vTags.copy(); val.extend([ proc['name'], str(proc['pid']), " ".join(proc["cmdline"]), datetime.datetime.fromtimestamp(proc["create_time"]).strftime("%d-%m-%Y %H:%M:%S") ])

               pth_c=GaugeMetricFamily("proc_threads_count", "The number of file descriptors currently opened by this process", labels=lbl)
               pth_u=GaugeMetricFamily("proc_threads_user_time", "time spent in user mode by process threads", labels=lbl)
               pth_s=GaugeMetricFamily("proc_threads_system_time", "time spent in kernel mode by process threads", labels=lbl)

               pmm_p=GaugeMetricFamily("proc_memory_percent", "process Memory utilization as a percentage ", labels=lbl)
               pcp_p=GaugeMetricFamily("proc_cpu_percent", "process CPU utilization as a percentage ", labels=lbl)
               pcn_e=GaugeMetricFamily("proc_connections_established_count", "connections opened and established by process", labels=lbl)
               pcn_o=GaugeMetricFamily("proc_connections_other_count", "connections opened and NOT established by process", labels=lbl)
               pfd_c=GaugeMetricFamily("proc_fd_count", "The number of file descriptors currently opened by this process", labels=lbl)
               pst_s=GaugeMetricFamily("proc_status", "The current process status (Status in Tag)", labels=lbl)

               pio_r=CounterMetricFamily("proc_io_read_count", "number of read operations performed by process", labels=lbl)
               pio_w=CounterMetricFamily("proc_io_write_count", "number of write operations performed by process", labels=lbl)
               pio_rb=CounterMetricFamily("proc_io_read_bytes", "number of bytes read by process", labels=lbl)
               pio_wb=CounterMetricFamily("proc_io_write_bytes", "number of bytes written by process", labels=lbl)
               pio_rc=CounterMetricFamily("proc_io_read_chars", "bytes which this process passed to read syscalls (doesn’t care about physical disk)", labels=lbl)
               pio_wc=CounterMetricFamily("proc_io_write_chars", "bytes which this process passed to write syscalls (doesn’t care about physical disk)", labels=lbl)

               pcp_u=GaugeMetricFamily("proc_cpu_user", "time spent in user mode", labels=lbl)
               pcp_s=GaugeMetricFamily("proc_cpu_system", "time spent in kernel mode", labels=lbl)
               pcp_cu=GaugeMetricFamily("proc_cpu_children_user", "user time of all child processes", labels=lbl)
               pcp_cs=GaugeMetricFamily("proc_cpu_children_system", "system time of all child processes", labels=lbl)
               pcp_io=GaugeMetricFamily("proc_cpu_iowait", "time spent waiting for blocking I/O to complete", labels=lbl)
               pcp_c=GaugeMetricFamily("proc_cpu", "what CPU this process is currently running on", labels=lbl)


               pmm_rs=GaugeMetricFamily("proc_mem_rss", "Resident Set Size, this is the non-swapped physical memory a process has used", labels=lbl)
               pmm_vm=GaugeMetricFamily("proc_mem_vms", "Virtual Memory Size, this is the total amount of virtual memory used by the process", labels=lbl)
               pmm_sh=GaugeMetricFamily("proc_mem_shared", "memory that could be potentially shared with other processes", labels=lbl)
               pmm_tx=GaugeMetricFamily("proc_mem_text", "TRS (text resident set) the amount of memory devoted to executable code", labels=lbl)
               pmm_dt=GaugeMetricFamily("proc_mem_data", "DRS (data resident set) the amount of physical memory devoted to other than executable code", labels=lbl)
               pmm_lb=GaugeMetricFamily("proc_mem_lib", "memory used by shared libraries", labels=lbl)
               pmm_di=GaugeMetricFamily("proc_mem_dirty", "number of dirty pages", labels=lbl)
               pmm_us=GaugeMetricFamily("proc_mem_uss", "Unique Set Size, this is the memory which is unique to a process", labels=lbl)
               pmm_ps=GaugeMetricFamily("proc_mem_pss", "Proportional Set Size, is the amount of memory shared with other processes", labels=lbl)
               pmm_sw=GaugeMetricFamily("proc_mem_swap", "amount of memory that has been swapped out to disk", labels=lbl)

               pcx_v=CounterMetricFamily("proc_ctx_voluntary", "number of voluntary context switches performed by this process", labels=lbl)
               pcx_i=CounterMetricFamily("proc_ctx_involuntary", "number of involuntary context switches performed by this process", labels=lbl)

               status=["running","sleeping","disk_sleep","stopped","tracing_stop","zombie","dead","wake_kill","waking","parked","idle"]

               lthreads={'n':0, 'us':0, 'sys':0 }
               for t in proc['threads']:
                  lthreads['n'] += 1
                  lthreads['us'] += t.user_time
                  lthreads['sys'] += t.system_time
                
               lconn={'n':0, 'estab':0, 'oth':0 }
               for c in proc['connections']:
                  lconn['n'] += 1
                  lconn['estab'] += 1 if c.status == 'ESTABLISHED' else 0
                  lconn['oth'] += 1 if c.status != 'ESTABLISHED' else 0
               
               pth_c.add_metric(val, proc['num_threads'])
               pth_u.add_metric(val, lthreads['us'])
               pth_s.add_metric(val, lthreads['sys'])
               pmm_p.add_metric(val, proc['memory_percent'])
               pcp_p.add_metric(val, proc['cpu_percent'])
               pcn_e.add_metric(val, lconn['estab'])
               pcn_o.add_metric(val, lconn['oth'])
               pfd_c.add_metric(val, proc['num_fds'])
               lblstat=lbl.copy(); lblstat.extend(["status"])
               valstat=val.copy(); valstat.extend([ proc['status'] ])
               pst_s.add_metric(val, status.index(proc['status']))
               pio_r.add_metric(val, proc['io_counters'].read_count)
               pio_w.add_metric(val, proc['io_counters'].write_count)
               pio_rb.add_metric(val, proc['io_counters'].read_bytes)
               pio_wb.add_metric(val, proc['io_counters'].write_bytes)
               pio_rc.add_metric(val, proc['io_counters'].read_chars)
               pio_wc.add_metric(val, proc['io_counters'].write_chars)
               pcp_u.add_metric(val, proc['cpu_times'].user)
               pcp_s.add_metric(val, proc['cpu_times'].system)
               pcp_cu.add_metric(val, proc['cpu_times'].children_user)
               pcp_cs.add_metric(val, proc['cpu_times'].children_system)
               pcp_io.add_metric(val, self.defs(proc['cpu_times'],"iowait"))
               pcp_c.add_metric(val, proc['cpu_num'])
               pmm_rs.add_metric(val, proc['memory_full_info'].rss)
               pmm_vm.add_metric(val, proc['memory_full_info'].vms)
               pmm_sh.add_metric(val, proc['memory_full_info'].shared)
               pmm_tx.add_metric(val, proc['memory_full_info'].text)
               pmm_dt.add_metric(val, proc['memory_full_info'].data)
               pmm_lb.add_metric(val, proc['memory_full_info'].lib)
               pmm_di.add_metric(val, proc['memory_full_info'].dirty)
               pmm_us.add_metric(val, proc['memory_full_info'].uss)
               pmm_ps.add_metric(val, proc['memory_full_info'].pss)
               pmm_sw.add_metric(val, proc['memory_full_info'].swap)
               pcx_v.add_metric(val, proc['num_ctx_switches'].voluntary)
               pcx_i.add_metric(val, proc['num_ctx_switches'].involuntary)

               yield from (pth_c, pth_u, pth_s, pmm_p, pcp_p, pcn_e, pcn_o, pfd_c, pst_s, pio_r, pio_w, pio_rb, pio_wb, pio_rc, pio_wc, pcp_u, pcp_s, pcp_cu, pcp_cs, pcp_io, pcp_c, pmm_rs, pmm_vm, pmm_sh, pmm_tx, pmm_dt, pmm_lb, pmm_di, pmm_us, pmm_ps, pmm_sw, pcx_v, pcx_i)

        mUrl=list(filter(lambda x: x!="get",reduce(lambda a,b: a+b.split(), filter(lambda x: x.startswith("get "), Cfg['Collect']) ,[] )))
        if mUrl:
           for url in mUrl:
       #        start = time.perf_counter()
       #        response = requests.get(url, timeout=timeout)
       #        response_json=response.json()
       #        cat_data=response_json['text']
               print("GET "+url)
       #        print(response.elapsed)
       #        print(response.elapsed.total_seconds())
       #        requests.status_code
       #        request_time = time.perf_counter() - start
       #        self.logger.info("Request completed in {0:.0f}ms".format(request_time)

        credis=re.match(r"redis +([^:]+)(?:(?::(\d+)|)(?:/(\d+)|))", next((o for o in Cfg["Collect"] if o.lower().startswith("redis ")),""), flags=re.IGNORECASE)
        if credis:
           ndb=credis.group(3) or 0
           r = redis.StrictRedis(host=credis.group(1), port=credis.group(2) or 6379, db=ndb)
           rinfo=r.execute_command('INFO')
           RRet={}

           lbl=self.kTags.copy(); lbl.extend(["host","database"])
           val=self.vTags.copy(); val.extend([ credis.group(1), ndb ])

           lblredis=lbl.copy(); lblredis.extend(["version","mode","os","role"])
           valredis=val.copy(); valredis.extend([ rinfo['redis_version'], rinfo['redis_mode'], rinfo['os'], rinfo['role'] ])

           RRet["status"]=GaugeMetricFamily("redis_status", "redis server status", labels=lblredis)
           RRet["status"].add_metric(valredis, 1)

           RRet["uptime_in_seconds"]=GaugeMetricFamily("redis_uptime_in_seconds",  "Number of seconds since Redis server start", labels=lbl)
           RRet["uptime_in_days"]=GaugeMetricFamily("redis_uptime_in_days",  "Number of days since Redis server start", labels=lbl)
           RRet["connected_clients"]=GaugeMetricFamily("redis_connected_clients",  "Number of client connections", labels=lbl)
           RRet["blocked_clients"]=GaugeMetricFamily("redis_blocked_clients",  "Number of clients pending on a blocking call", labels=lbl)
           RRet["used_memory"]=GaugeMetricFamily("redis_used_memory",  "Total number of bytes allocated by Redis using its allocator", labels=lbl)
           RRet["used_memory_rss"]=GaugeMetricFamily("redis_used_memory_rss",  "Number of bytes that Redis allocated as seen by the operating system", labels=lbl)
           RRet["used_memory_peak"]=GaugeMetricFamily("redis_used_memory_peak",  "Peak memory consumed by Redis (in bytes)", labels=lbl)
           RRet["used_memory_overhead"]=GaugeMetricFamily("redis_used_memory_overhead",  "The sum in bytes of all overheads that the server allocated for managing its internal data structures", labels=lbl)
           RRet["used_memory_startup"]=GaugeMetricFamily("redis_used_memory_startup",  "Initial amount of memory consumed by Redis at startup in bytes", labels=lbl)
           RRet["used_memory_dataset"]=GaugeMetricFamily("redis_used_memory_dataset",  "The size in bytes of the dataset", labels=lbl)
           RRet["allocator_allocated"]=GaugeMetricFamily("redis_allocator_allocated",  "Total bytes allocated form the allocator, including internal-fragmentation", labels=lbl)
           RRet["allocator_active"]=GaugeMetricFamily("redis_allocator_active",  "Total bytes in the allocator active pages", labels=lbl)
           RRet["allocator_resident"]=GaugeMetricFamily("redis_allocator_resident",  "Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS", labels=lbl)
           RRet["total_system_memory"]=GaugeMetricFamily("redis_total_system_memory",  "The total amount of memory that the Redis host has", labels=lbl)
           RRet["used_memory_lua"]=GaugeMetricFamily("redis_used_memory_lua",  "Number of bytes used by the Lua engine", labels=lbl)
           RRet["used_memory_scripts"]=GaugeMetricFamily("redis_used_memory_scripts",  "Number of bytes used by cached Lua scripts", labels=lbl)
           RRet["number_of_cached_scripts"]=GaugeMetricFamily("redis_number_of_cached_scripts",  "Number of loaded Scripts", labels=lbl)
           RRet["allocator_frag_ratio"]=GaugeMetricFamily("redis_allocator_frag_ratio",  "Ratio between allocator_active and allocator_allocated", labels=lbl)
           RRet["allocator_frag_bytes"]=GaugeMetricFamily("redis_allocator_frag_bytes",  "Delta between allocator_active and allocator_allocated", labels=lbl)
           RRet["allocator_rss_ratio"]=GaugeMetricFamily("redis_allocator_rss_ratio",  "Ratio between allocator_resident and allocator_active", labels=lbl)
           RRet["allocator_rss_bytes"]=GaugeMetricFamily("redis_allocator_rss_bytes",  "Delta between allocator_resident and allocator_active", labels=lbl)
           RRet["rss_overhead_ratio"]=GaugeMetricFamily("redis_rss_overhead_ratio",  "Ratio between used_memory_rss (the process RSS) and allocator_resident", labels=lbl)
           RRet["rss_overhead_bytes"]=GaugeMetricFamily("redis_rss_overhead_bytes",  "Delta between used_memory_rss (the process RSS) and allocator_resident", labels=lbl)
           RRet["mem_fragmentation_ratio"]=GaugeMetricFamily("redis_mem_fragmentation_ratio",  "Ratio between used_memory_rss and used_memory", labels=lbl)
           RRet["mem_fragmentation_bytes"]=GaugeMetricFamily("redis_mem_fragmentation_bytes",  "Delta between used_memory_rss and used_memory", labels=lbl)
           RRet["mem_not_counted_for_evict"]=GaugeMetricFamily("redis_mem_not_counted_for_evict",  "Used memory that's not counted for key eviction", labels=lbl)
           RRet["mem_replication_backlog"]=GaugeMetricFamily("redis_mem_replication_backlog",  "Memory used by replication backlog", labels=lbl)
           RRet["mem_clients_slaves"]=GaugeMetricFamily("redis_mem_clients_slaves",  "Memory used by replica clients", labels=lbl)
           RRet["mem_clients_normal"]=GaugeMetricFamily("redis_mem_clients_normal",  "Memory used by normal clients", labels=lbl)
           RRet["mem_aof_buffer"]=GaugeMetricFamily("redis_mem_aof_buffer",  "Transient memory used for AOF and AOF rewrite buffers", labels=lbl)
           RRet["lazyfree_pending_objects"]=GaugeMetricFamily("redis_lazyfree_pending_objects",  "The number of objects waiting to be freed", labels=lbl)
           RRet["rdb_changes_since_last_save"]=GaugeMetricFamily("redis_rdb_changes_since_last_save",  "Number of changes since the last dump", labels=lbl)
           RRet["rdb_bgsave_in_progress"]=GaugeMetricFamily("redis_rdb_bgsave_in_progress",  "Flag indicating a RDB save is on-going", labels=lbl)
           RRet["rdb_last_save_time"]=GaugeMetricFamily("redis_rdb_last_save_time",  "Epoch-based timestamp of last successful RDB save", labels=lbl)
           RRet["rdb_last_bgsave_time_sec"]=GaugeMetricFamily("redis_rdb_last_bgsave_time_sec",  "Duration of the last RDB save operation in seconds", labels=lbl)
           RRet["rdb_current_bgsave_time_sec"]=GaugeMetricFamily("redis_rdb_current_bgsave_time_sec",  "Duration of the on-going RDB save operation if any", labels=lbl)
           RRet["rdb_last_cow_size"]=GaugeMetricFamily("redis_rdb_last_cow_size",  "The size in bytes of copy-on-write memory during the last RDB save operation", labels=lbl)
           RRet["aof_rewrite_in_progress"]=GaugeMetricFamily("redis_aof_rewrite_in_progress",  "Flag indicating a AOF rewrite operation is on-going", labels=lbl)
           RRet["aof_rewrite_scheduled"]=GaugeMetricFamily("redis_aof_rewrite_scheduled",  "Flag indicating an AOF rewrite operation will be scheduled once the on-going RDB save is complete", labels=lbl)
           RRet["aof_last_rewrite_time_sec"]=GaugeMetricFamily("redis_aof_last_rewrite_time_sec",  "Duration of the last AOF rewrite operation in seconds", labels=lbl)
           RRet["aof_current_rewrite_time_sec"]=GaugeMetricFamily("redis_aof_current_rewrite_time_sec",  "Duration of the on-going AOF rewrite operation if any", labels=lbl)
           RRet["aof_last_cow_size"]=GaugeMetricFamily("redis_aof_last_cow_size",  "The size in bytes of copy-on-write memory during the last AOF rewrite operation", labels=lbl)
           RRet["total_connections_received"]=GaugeMetricFamily("redis_total_connections_received",  "Total number of connections accepted by the server", labels=lbl)
           RRet["total_commands_processed"]=GaugeMetricFamily("redis_total_commands_processed",  "Total number of commands processed by the server", labels=lbl)
           RRet["instantaneous_ops_per_sec"]=GaugeMetricFamily("redis_instantaneous_ops_per_sec",  "Number of commands processed per second", labels=lbl)
           RRet["total_net_input_bytes"]=GaugeMetricFamily("redis_total_net_input_bytes",  "The total number of bytes read from the network", labels=lbl)
           RRet["total_net_output_bytes"]=GaugeMetricFamily("redis_total_net_output_bytes",  "The total number of bytes written to the network", labels=lbl)
           RRet["instantaneous_input_kbps"]=GaugeMetricFamily("redis_instantaneous_input_kbps",  "The network's read rate per second in KB/sec", labels=lbl)
           RRet["instantaneous_output_kbps"]=GaugeMetricFamily("redis_instantaneous_output_kbps",  "The network's write rate per second in KB/sec", labels=lbl)
           RRet["rejected_connections"]=GaugeMetricFamily("redis_rejected_connections",  "Number of connections rejected because of maxclients limit", labels=lbl)
           RRet["sync_full"]=GaugeMetricFamily("redis_sync_full",  "The number of full resyncs with replicas", labels=lbl)
           RRet["sync_partial_ok"]=GaugeMetricFamily("redis_sync_partial_ok",  "The number of accepted partial resync requests", labels=lbl)
           RRet["sync_partial_err"]=GaugeMetricFamily("redis_sync_partial_err",  "The number of denied partial resync requests", labels=lbl)
           RRet["expired_keys"]=GaugeMetricFamily("redis_expired_keys",  "Total number of key expiration events", labels=lbl)
           RRet["expired_stale_perc"]=GaugeMetricFamily("redis_expired_stale_perc",  "The percentage of keys probably expired", labels=lbl)
           RRet["expired_time_cap_reached_count"]=GaugeMetricFamily("redis_expired_time_cap_reached_count",  "The count of times that active expiry cycles have stopped early", labels=lbl)
           RRet["evicted_keys"]=GaugeMetricFamily("redis_evicted_keys",  "Number of evicted keys due to maxmemory limit", labels=lbl)
           RRet["keyspace_hits"]=GaugeMetricFamily("redis_keyspace_hits",  "Number of successful lookup of keys in the main dictionary", labels=lbl)
           RRet["keyspace_misses"]=GaugeMetricFamily("redis_keyspace_misses",  "Number of failed lookup of keys in the main dictionary", labels=lbl)
           RRet["pubsub_channels"]=GaugeMetricFamily("redis_pubsub_channels",  "Global number of pub/sub channels with client subscriptions", labels=lbl)
           RRet["pubsub_patterns"]=GaugeMetricFamily("redis_pubsub_patterns",  "Global number of pub/sub pattern with client subscriptions", labels=lbl)
           RRet["latest_fork_usec"]=GaugeMetricFamily("redis_latest_fork_usec",  "Duration of the latest fork operation in microseconds", labels=lbl)
           RRet["migrate_cached_sockets"]=GaugeMetricFamily("redis_migrate_cached_sockets",  "The number of sockets open for MIGRATE purposes", labels=lbl)
           RRet["slave_expires_tracked_keys"]=GaugeMetricFamily("redis_slave_expires_tracked_keys",  "The number of keys tracked for expiry purposes", labels=lbl)
           RRet["connected_slaves"]=GaugeMetricFamily("redis_connected_slaves",  "Number of connected replicas", labels=lbl)
           RRet["master_repl_offset"]=GaugeMetricFamily("redis_master_repl_offset",  "The server's current replication offset", labels=lbl)
           RRet["second_repl_offset"]=GaugeMetricFamily("redis_second_repl_offset",  "The offset up to which replication IDs are accepted", labels=lbl)
           RRet["repl_backlog_size"]=GaugeMetricFamily("redis_repl_backlog_size",  "Total size in bytes of the replication backlog buffer", labels=lbl)
           RRet["repl_backlog_first_byte_offset"]=GaugeMetricFamily("redis_repl_backlog_first_byte_offset",  "The master offset of the replication backlog buffer", labels=lbl)
           RRet["repl_backlog_histlen"]=GaugeMetricFamily("redis_repl_backlog_histlen",  "Size in bytes of the data in the replication backlog buffer", labels=lbl)
           RRet["used_cpu_sys"]=GaugeMetricFamily("redis_used_cpu_sys",  "System CPU consumed by the Redis server", labels=lbl)
           RRet["used_cpu_user"]=GaugeMetricFamily("redis_used_cpu_user",  "User CPU consumed by the Redis server (sum of user CPU consumed by all threads of the server process)", labels=lbl)
           RRet["used_cpu_sys_children"]=GaugeMetricFamily("redis_used_cpu_sys_children",  "System CPU consumed by the background processes", labels=lbl)
           RRet["used_cpu_user_children"]=GaugeMetricFamily("redis_used_cpu_user_children",  "User CPU consumed by the background processes", labels=lbl)
           RRet["db"+ndb+"keys"]=GaugeMetricFamily("redis_database_keys",  "number of database keys", labels=lbl)
           RRet["db"+ndb+"expires"]=GaugeMetricFamily("redis_database_expires",  "number of database with expiration", labels=lbl)
           RRet["db"+ndb+"avg_ttl"]=GaugeMetricFamily("redis_database_avg_ttl",  "database TTL average", labels=lbl)
           #------------------
           RRet["uptime_in_seconds"].add_metric(val, rinfo["uptime_in_seconds"])
           RRet["uptime_in_days"].add_metric(val, rinfo["uptime_in_days"])
           RRet["connected_clients"].add_metric(val, rinfo["connected_clients"])
           RRet["blocked_clients"].add_metric(val, rinfo["blocked_clients"])
           RRet["used_memory"].add_metric(val, rinfo["used_memory"])
           RRet["used_memory_rss"].add_metric(val, rinfo["used_memory_rss"])
           RRet["used_memory_peak"].add_metric(val, rinfo["used_memory_peak"])
           RRet["used_memory_overhead"].add_metric(val, rinfo["used_memory_overhead"])
           RRet["used_memory_startup"].add_metric(val, rinfo["used_memory_startup"])
           RRet["used_memory_dataset"].add_metric(val, rinfo["used_memory_dataset"])
           RRet["allocator_allocated"].add_metric(val, rinfo["allocator_allocated"])
           RRet["allocator_active"].add_metric(val, rinfo["allocator_active"])
           RRet["allocator_resident"].add_metric(val, rinfo["allocator_resident"])
           RRet["total_system_memory"].add_metric(val, rinfo["total_system_memory"])
           RRet["used_memory_lua"].add_metric(val, rinfo["used_memory_lua"])
           RRet["used_memory_scripts"].add_metric(val, rinfo["used_memory_scripts"])
           RRet["number_of_cached_scripts"].add_metric(val, rinfo["number_of_cached_scripts"])
           RRet["allocator_frag_ratio"].add_metric(val, rinfo["allocator_frag_ratio"])
           RRet["allocator_frag_bytes"].add_metric(val, rinfo["allocator_frag_bytes"])
           RRet["allocator_rss_ratio"].add_metric(val, rinfo["allocator_rss_ratio"])
           RRet["allocator_rss_bytes"].add_metric(val, rinfo["allocator_rss_bytes"])
           RRet["rss_overhead_ratio"].add_metric(val, rinfo["rss_overhead_ratio"])
           RRet["rss_overhead_bytes"].add_metric(val, rinfo["rss_overhead_bytes"])
           RRet["mem_fragmentation_ratio"].add_metric(val, rinfo["mem_fragmentation_ratio"])
           RRet["mem_fragmentation_bytes"].add_metric(val, rinfo["mem_fragmentation_bytes"])
           RRet["mem_not_counted_for_evict"].add_metric(val, rinfo["mem_not_counted_for_evict"])
           RRet["mem_replication_backlog"].add_metric(val, rinfo["mem_replication_backlog"])
           RRet["mem_clients_slaves"].add_metric(val, rinfo["mem_clients_slaves"])
           RRet["mem_clients_normal"].add_metric(val, rinfo["mem_clients_normal"])
           RRet["mem_aof_buffer"].add_metric(val, rinfo["mem_aof_buffer"])
           RRet["lazyfree_pending_objects"].add_metric(val, rinfo["lazyfree_pending_objects"])
           RRet["rdb_changes_since_last_save"].add_metric(val, rinfo["rdb_changes_since_last_save"])
           RRet["rdb_bgsave_in_progress"].add_metric(val, rinfo["rdb_bgsave_in_progress"])
           RRet["rdb_last_save_time"].add_metric(val, rinfo["rdb_last_save_time"])
           RRet["rdb_last_bgsave_time_sec"].add_metric(val, rinfo["rdb_last_bgsave_time_sec"])
           RRet["rdb_current_bgsave_time_sec"].add_metric(val, rinfo["rdb_current_bgsave_time_sec"])
           RRet["rdb_last_cow_size"].add_metric(val, rinfo["rdb_last_cow_size"])
           RRet["aof_rewrite_in_progress"].add_metric(val, rinfo["aof_rewrite_in_progress"])
           RRet["aof_rewrite_scheduled"].add_metric(val, rinfo["aof_rewrite_scheduled"])
           RRet["aof_last_rewrite_time_sec"].add_metric(val, rinfo["aof_last_rewrite_time_sec"])
           RRet["aof_current_rewrite_time_sec"].add_metric(val, rinfo["aof_current_rewrite_time_sec"])
           RRet["aof_last_cow_size"].add_metric(val, rinfo["aof_last_cow_size"])
           RRet["total_connections_received"].add_metric(val, rinfo["total_connections_received"])
           RRet["total_commands_processed"].add_metric(val, rinfo["total_commands_processed"])
           RRet["instantaneous_ops_per_sec"].add_metric(val, rinfo["instantaneous_ops_per_sec"])
           RRet["total_net_input_bytes"].add_metric(val, rinfo["total_net_input_bytes"])
           RRet["total_net_output_bytes"].add_metric(val, rinfo["total_net_output_bytes"])
           RRet["instantaneous_input_kbps"].add_metric(val, rinfo["instantaneous_input_kbps"])
           RRet["instantaneous_output_kbps"].add_metric(val, rinfo["instantaneous_output_kbps"])
           RRet["rejected_connections"].add_metric(val, rinfo["rejected_connections"])
           RRet["sync_full"].add_metric(val, rinfo["sync_full"])
           RRet["sync_partial_ok"].add_metric(val, rinfo["sync_partial_ok"])
           RRet["sync_partial_err"].add_metric(val, rinfo["sync_partial_err"])
           RRet["expired_keys"].add_metric(val, rinfo["expired_keys"])
           RRet["expired_stale_perc"].add_metric(val, rinfo["expired_stale_perc"])
           RRet["expired_time_cap_reached_count"].add_metric(val, rinfo["expired_time_cap_reached_count"])
           RRet["evicted_keys"].add_metric(val, rinfo["evicted_keys"])
           RRet["keyspace_hits"].add_metric(val, rinfo["keyspace_hits"])
           RRet["keyspace_misses"].add_metric(val, rinfo["keyspace_misses"])
           RRet["pubsub_channels"].add_metric(val, rinfo["pubsub_channels"])
           RRet["pubsub_patterns"].add_metric(val, rinfo["pubsub_patterns"])
           RRet["latest_fork_usec"].add_metric(val, rinfo["latest_fork_usec"])
           RRet["migrate_cached_sockets"].add_metric(val, rinfo["migrate_cached_sockets"])
           RRet["slave_expires_tracked_keys"].add_metric(val, rinfo["slave_expires_tracked_keys"])
           RRet["connected_slaves"].add_metric(val, rinfo["connected_slaves"])
           RRet["master_repl_offset"].add_metric(val, rinfo["master_repl_offset"])
           RRet["second_repl_offset"].add_metric(val, rinfo["second_repl_offset"])
           RRet["repl_backlog_size"].add_metric(val, rinfo["repl_backlog_size"])
           RRet["repl_backlog_first_byte_offset"].add_metric(val, rinfo["repl_backlog_first_byte_offset"])
           RRet["repl_backlog_histlen"].add_metric(val, rinfo["repl_backlog_histlen"])
           RRet["used_cpu_sys"].add_metric(val, rinfo["used_cpu_sys"])
           RRet["used_cpu_user"].add_metric(val, rinfo["used_cpu_user"])
           RRet["used_cpu_sys_children"].add_metric(val, rinfo["used_cpu_sys_children"])
           RRet["used_cpu_user_children"].add_metric(val, rinfo["used_cpu_user_children"])
           RRet["db"+ndb+"keys"].add_metric(val, rinfo["db"+ndb]["keys"])
           RRet["db"+ndb+"expires"].add_metric(val, rinfo["db"+ndb]["expires"])
           RRet["db"+ndb+"avg_ttl"].add_metric(val, rinfo["db"+ndb]["avg_ttl"])

           yield from ( RRet["status"], RRet["uptime_in_seconds"], RRet["uptime_in_days"], RRet["connected_clients"], RRet["blocked_clients"], RRet["used_memory"], RRet["used_memory_rss"], RRet["used_memory_peak"], RRet["used_memory_overhead"], RRet["used_memory_startup"], RRet["used_memory_dataset"], RRet["allocator_allocated"], RRet["allocator_active"], RRet["allocator_resident"], RRet["total_system_memory"], RRet["used_memory_lua"], RRet["used_memory_scripts"], RRet["number_of_cached_scripts"], RRet["allocator_frag_ratio"], RRet["allocator_frag_bytes"], RRet["allocator_rss_ratio"], RRet["allocator_rss_bytes"], RRet["rss_overhead_ratio"], RRet["rss_overhead_bytes"], RRet["mem_fragmentation_ratio"], RRet["mem_fragmentation_bytes"], RRet["mem_not_counted_for_evict"], RRet["mem_replication_backlog"], RRet["mem_clients_slaves"], RRet["mem_clients_normal"], RRet["mem_aof_buffer"], RRet["lazyfree_pending_objects"], RRet["rdb_changes_since_last_save"], RRet["rdb_bgsave_in_progress"], RRet["rdb_last_save_time"], RRet["rdb_last_bgsave_time_sec"], RRet["rdb_current_bgsave_time_sec"], RRet["rdb_last_cow_size"], RRet["aof_rewrite_in_progress"], RRet["aof_rewrite_scheduled"], RRet["aof_last_rewrite_time_sec"], RRet["aof_current_rewrite_time_sec"], RRet["aof_last_cow_size"], RRet["total_connections_received"], RRet["total_commands_processed"], RRet["instantaneous_ops_per_sec"], RRet["total_net_input_bytes"], RRet["total_net_output_bytes"], RRet["instantaneous_input_kbps"], RRet["instantaneous_output_kbps"], RRet["rejected_connections"], RRet["sync_full"], RRet["sync_partial_ok"], RRet["sync_partial_err"], RRet["expired_keys"], RRet["expired_stale_perc"], RRet["expired_time_cap_reached_count"], RRet["evicted_keys"], RRet["keyspace_hits"], RRet["keyspace_misses"], RRet["pubsub_channels"], RRet["pubsub_patterns"], RRet["latest_fork_usec"], RRet["migrate_cached_sockets"], RRet["slave_expires_tracked_keys"], RRet["connected_slaves"], RRet["master_repl_offset"], RRet["second_repl_offset"], RRet["repl_backlog_size"], RRet["repl_backlog_first_byte_offset"], RRet["repl_backlog_histlen"], RRet["used_cpu_sys"], RRet["used_cpu_user"], RRet["used_cpu_sys_children"], RRet["used_cpu_user_children"], RRet["db"+ndb+"keys"], RRet["db"+ndb+"expires"], RRet["db"+ndb+"avg_ttl"] )



def ReadConf(pfile=""):
    global Cfg
    for fl in glob.glob("config.yml")+glob.glob("config.yaml")+glob.glob(os.path.basename(__file__).rsplit('.', 1)[0]+".y*ml")+glob.glob(pfile):
        with open(fl, 'r') as f:
             try:
                c = {k.lower():v for k,v in yaml.safe_load(f).items()}
                if "port" in c: Cfg["Port"]=int(c['port'])
                if "frequency" in c: Cfg["Freq"]=int(c['frequency'])
                if "tags" in c: Cfg['Tags'].extend(c['tags'])
                if "collect" in c: Cfg['Collect'].extend(c['collect'])
             except yaml.YAMLError as error:
                print(error)


if __name__ == "__main__":
    ReadConf()
    start_http_server(Cfg["Port"])
    REGISTRY.register(CollectCPU())
 
    while True: 
        time.sleep(Cfg["Freq"])



